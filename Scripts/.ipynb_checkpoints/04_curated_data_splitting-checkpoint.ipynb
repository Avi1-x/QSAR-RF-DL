{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc37d429-5f70-4a86-b1d0-6699f27be634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81e4aa85-8d16-41b3-8f02-4ad9b7c45ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprinted_data_directory = '/Users/Avi/Dissertation/Data/Curated/Fingerprinted'\n",
    "\n",
    "scaffold_split_directory = '/Users/Avi/Dissertation/Data/Curated/Split/Scaffold'\n",
    "os.makedirs(scaffold_split_directory, exist_ok=True)\n",
    "\n",
    "random_split_directory = '/Users/Avi/Dissertation/Data/Curated/Split/Random'\n",
    "os.makedirs(random_split_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afc742d0-03ba-4eb6-a344-47010b114ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_CHEMBL4078 = pd.read_csv(os.path.join(fingerprinted_data_directory, 'Target_CHEMBL4078_Curated_Fingerprinted.csv'))\n",
    "target_CHEMBL279 = pd.read_csv(os.path.join(fingerprinted_data_directory, 'Target_CHEMBL279_Curated_Fingerprinted.csv'))\n",
    "target_CHEMBL5763 = pd.read_csv(os.path.join(fingerprinted_data_directory, 'Target_CHEMBL5763_Curated_Fingerprinted.csv'))\n",
    "target_CHEMBL240 = pd.read_csv(os.path.join(fingerprinted_data_directory, 'Target_CHEMBL240_Curated_Fingerprinted.csv'))\n",
    "target_CHEMBL4005 = pd.read_csv(os.path.join(fingerprinted_data_directory, 'Target_CHEMBL4005_Curated_Fingerprinted.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cece29-3e04-4205-b484-8b5af91c172a",
   "metadata": {},
   "source": [
    "### Scaffold Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "716e5552-7b59-4c86-8d0c-bfec741200ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaffold(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    scaffold = MurckoScaffold.GetScaffoldForMol(mol)\n",
    "    return Chem.MolToSmiles(scaffold)\n",
    "\n",
    "def allocate_indices(indices, set_size):\n",
    "    allocated_set = indices[:set_size]\n",
    "    remaining_indices = indices[set_size:]\n",
    "    return allocated_set, remaining_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b11a451-7680-4da8-bf2e-3cb2c433a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['CHEMBL4078', 'CHEMBL279', 'CHEMBL5763', 'CHEMBL240', 'CHEMBL4005']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "458b42d6-2af6-4c2e-8b1f-bbbcb6c14fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaffold split for CHEMBL4078 completed. Training set size: 3004, Test set size: 751\n",
      "Scaffold split for CHEMBL279 completed. Training set size: 2676, Test set size: 668\n",
      "Scaffold split for CHEMBL5763 completed. Training set size: 2160, Test set size: 540\n",
      "Scaffold split for CHEMBL240 completed. Training set size: 2254, Test set size: 563\n",
      "Scaffold split for CHEMBL4005 completed. Training set size: 2252, Test set size: 562\n"
     ]
    }
   ],
   "source": [
    "for target in targets:\n",
    "    # Load the fingerprinted data\n",
    "    df = pd.read_csv(os.path.join(fingerprinted_data_directory, f'Target_{target}_Curated_Fingerprinted.csv'))\n",
    "    \n",
    "    # Group by scaffolds\n",
    "    scaffold_to_molecules = defaultdict(list)\n",
    "    for idx, row in df.iterrows():\n",
    "        smiles = row['canonical_smiles']\n",
    "        scaffold = get_scaffold(smiles)\n",
    "        scaffold_to_molecules[scaffold].append(idx)\n",
    "    \n",
    "    scaffold_bins = list(scaffold_to_molecules.items())\n",
    "    np.random.shuffle(scaffold_bins)\n",
    "    \n",
    "    total_size = len(df)\n",
    "    test_size = int(0.2 * total_size)\n",
    "    train_size = total_size - test_size\n",
    "    \n",
    "    train_indices = []\n",
    "    remaining_bins = []\n",
    "    \n",
    "    for scaffold, indices in scaffold_bins:\n",
    "        if len(indices) > test_size // 2:\n",
    "            train_indices.extend(indices)\n",
    "        else:\n",
    "            remaining_bins.append((scaffold, indices))\n",
    "    \n",
    "    np.random.shuffle(remaining_bins)\n",
    "    remaining_indices = [idx for scaffold, indices in remaining_bins for idx in indices]\n",
    "    \n",
    "    test_indices, remaining_indices = allocate_indices(remaining_indices, test_size)\n",
    "    train_indices.extend(remaining_indices)\n",
    "    \n",
    "    train_df = df.iloc[train_indices]\n",
    "    test_df = df.iloc[test_indices]\n",
    "    \n",
    "    # Save the split data\n",
    "    train_df.to_csv(os.path.join(scaffold_split_directory, f'{target}_Train_Scaffold.csv'), index=False)\n",
    "    test_df.to_csv(os.path.join(scaffold_split_directory, f'{target}_Test_Scaffold.csv'), index=False)\n",
    "    \n",
    "    print(f\"Scaffold split for {target} completed. Training set size: {len(train_df)}, Test set size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3c71d9-a70f-4b87-817b-e27884480da2",
   "metadata": {},
   "source": [
    "### Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e17d6029-3ebd-452d-bd0d-c59f198ae035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random split for CHEMBL4078 completed. Training set size: 3004, Test set size: 751\n",
      "Random split for CHEMBL279 completed. Training set size: 2675, Test set size: 669\n",
      "Random split for CHEMBL5763 completed. Training set size: 2160, Test set size: 540\n",
      "Random split for CHEMBL240 completed. Training set size: 2253, Test set size: 564\n",
      "Random split for CHEMBL4005 completed. Training set size: 2251, Test set size: 563\n"
     ]
    }
   ],
   "source": [
    "def random_split(target):\n",
    "    df = pd.read_csv(os.path.join(fingerprinted_data_directory, f'Target_{target}_Curated_Fingerprinted.csv'))\n",
    "    \n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    train_df.to_csv(os.path.join(random_split_directory, f'{target}_Train_Random.csv'), index=False)\n",
    "    test_df.to_csv(os.path.join(random_split_directory, f'{target}_Test_Random.csv'), index=False)\n",
    "    \n",
    "    print(f\"Random split for {target} completed. Training set size: {len(train_df)}, Test set size: {len(test_df)}\")\n",
    "\n",
    "for target in targets:\n",
    "    random_split(target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
