{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc37d429-5f70-4a86-b1d0-6699f27be634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca58e22-042e-4616-bfdf-d943b32f6d38",
   "metadata": {},
   "source": [
    "# Directory Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e064a6dc-f895-4845-b2e9-a85097ca0f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/Avi/Dissertation/Data'\n",
    "fingerprinted_data_directory = os.path.join(base_dir, 'Curated/Fingerprinted')\n",
    "scaffold_test_data_directory = os.path.join(base_dir, 'Curated/Test_Data/Scaffold_Split')\n",
    "random_test_data_directory = os.path.join(base_dir, 'Curated/Test_Data/Random_Split')\n",
    "train_data_directory = os.path.join(base_dir, 'Curated/Train_Data')\n",
    "\n",
    "for directory in [scaffold_test_data_directory, random_test_data_directory, train_data_directory]:\n",
    "    os.makedirs(directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f081ea41-c859-4019-b802-07c6e1cdfad5",
   "metadata": {},
   "source": [
    "# Assigning Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3c67d5f-9a10-4c7c-a98a-25cf52626f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['CHEMBL4078', 'CHEMBL279', 'CHEMBL5763', 'CHEMBL240', 'CHEMBL4005']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f942817-57eb-42fe-b808-8ce8cf822342",
   "metadata": {},
   "source": [
    "# Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8abfc479-f8c4-43a1-8803-bed106c68906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaffold(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    scaffold = MurckoScaffold.GetScaffoldForMol(mol)\n",
    "    return Chem.MolToSmiles(scaffold)\n",
    "\n",
    "def allocate_indices(indices, set_size):\n",
    "    return indices[:set_size], indices[set_size:]\n",
    "\n",
    "def process_target(target, random_state=42):\n",
    "    df = pd.read_csv(os.path.join(fingerprinted_data_directory, f'Target_{target}_Curated_Fingerprinted.csv'))\n",
    "    \n",
    "    scaffold_to_molecules = defaultdict(list)\n",
    "    for idx, smiles in enumerate(df['canonical_smiles']):\n",
    "        scaffold = get_scaffold(smiles)\n",
    "        scaffold_to_molecules[scaffold].append(idx)\n",
    "    \n",
    "    scaffold_bins = list(scaffold_to_molecules.items())\n",
    "    np.random.RandomState(random_state).shuffle(scaffold_bins)\n",
    "    \n",
    "    total_size = len(df)\n",
    "    test_size = int(0.2 * total_size)\n",
    "    \n",
    "    test_indices = []\n",
    "    train_indices = []\n",
    "    \n",
    "    for scaffold, indices in scaffold_bins:\n",
    "        if len(test_indices) + len(indices) <= test_size:\n",
    "            test_indices.extend(indices)\n",
    "        else:\n",
    "            train_indices.extend(indices)\n",
    "    \n",
    "    train_df = df.iloc[train_indices]\n",
    "    scaffold_test_df = df.iloc[test_indices]\n",
    "    \n",
    "    scaffold_test_df.to_csv(os.path.join(scaffold_test_data_directory, f'{target}_Test_Scaffold.csv'), index=False)\n",
    "        \n",
    "    random_train_df, random_test_df = train_test_split(train_df, test_size=0.25, random_state=random_state)\n",
    "    \n",
    "    random_test_df.to_csv(os.path.join(random_test_data_directory, f'{target}_Test_Random.csv'), index=False)\n",
    "    random_train_df.to_csv(os.path.join(train_data_directory, f'{target}_Train.csv'), index=False)\n",
    "    \n",
    "    return len(random_train_df), len(scaffold_test_df), len(random_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c50b548-3ed8-452a-9436-44f5623d8ac3",
   "metadata": {},
   "source": [
    "# Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "458b42d6-2af6-4c2e-8b1f-bbbcb6c14fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split for CHEMBL4078 completed. Training set size: 2230, Scaffold-Split Test set size: 743, Random-Split Test set size: 744\n",
      "Data split for CHEMBL279 completed. Training set size: 1961, Scaffold-Split Test set size: 653, Random-Split Test set size: 654\n",
      "Data split for CHEMBL5763 completed. Training set size: 1605, Scaffold-Split Test set size: 534, Random-Split Test set size: 535\n",
      "Data split for CHEMBL240 completed. Training set size: 1629, Scaffold-Split Test set size: 543, Random-Split Test set size: 543\n",
      "Data split for CHEMBL4005 completed. Training set size: 1641, Scaffold-Split Test set size: 546, Random-Split Test set size: 547\n"
     ]
    }
   ],
   "source": [
    "for target in targets:\n",
    "    train_size, scaffold_test_size, random_test_size = process_target(target)\n",
    "    print(f\"Data split for {target} completed. Training set size: {train_size}, \"\n",
    "          f\"Scaffold-Split Test set size: {scaffold_test_size}, \"\n",
    "          f\"Random-Split Test set size: {random_test_size}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
