{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21f03190-05b4-41ee-9761-acbad4187ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00403b5-9239-42e2-a546-4211a336c022",
   "metadata": {},
   "source": [
    "# Directory Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b959fb72-10e3-4002-83d3-a1622e6eb15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/Avi/Dissertation'\n",
    "\n",
    "results_dirs = {\n",
    "    \"Curated_RF_Classification_Results\": os.path.join(base_dir, 'Results/Model_Performance/Curated/Random_Forest/Classification'),\n",
    "    \"Curated_RF_Regression_Results\": os.path.join(base_dir, 'Results/Model_Performance/Curated/Random_Forest/Regression'),\n",
    "    \"Curated_ChemProp_Classification_Results\": os.path.join(base_dir, 'Results/Model_Performance/Curated/ChemProp/Classification'),\n",
    "    \"Curated_ChemProp_Regression_Results\": os.path.join(base_dir, 'Results/Model_Performance/Curated/ChemProp/Regression'),\n",
    "    \"Non_Curated_RF_Classification_Results\": os.path.join(base_dir, 'Results/Model_Performance/Non_Curated/Random_Forest/Classification'),\n",
    "    \"Non_Curated_RF_Regression_Results\": os.path.join(base_dir, 'Results/Model_Performance/Non_Curated/Random_Forest/Regression'),\n",
    "    \"Non_Curated_ChemProp_Classification_Results\": os.path.join(base_dir, 'Results/Model_Performance/Non_Curated/ChemProp/Classification'),\n",
    "    \"Non_Curated_ChemProp_Regression_Results\": os.path.join(base_dir, 'Results/Model_Performance/Non_Curated/ChemProp/Regression')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "049c2a79-39ed-46a5-8a68-45387243dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'Classification': ['accuracy', 'precision', 'recall', 'f1', 'auroc', 'auprc'],\n",
    "    'Regression': ['mse', 'rmse', 'r2', 'mae']\n",
    "}\n",
    "\n",
    "fingerprint_types = ['ECFP', 'MACCS KEYS', 'AP2', 'AP3', 'AP2+AP3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c210bbd1-65f2-4ee5-8167-0519ff0b573f",
   "metadata": {},
   "source": [
    "# Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db9e54f7-1105-4530-a2d6-2e5715674128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_files(directory: str) -> pd.DataFrame:\n",
    "    df = pd.concat([pd.read_csv(os.path.join(directory, f)) for f in os.listdir(directory) if f.endswith('.csv')])\n",
    "    df = df[~df['split'].str.lower().str.contains('train')]\n",
    "    return df\n",
    "\n",
    "def aggregate_metrics(df: pd.DataFrame, metrics: List[str]) -> Dict[str, Dict[str, float]]:\n",
    "    df.columns = df.columns.str.lower()\n",
    "    return {metric: {\"mean\": df[metric].mean(), \"std\": df[metric].std()} \n",
    "            for metric in metrics if metric in df.columns}\n",
    "\n",
    "def save_results(results: pd.DataFrame, output_dir: str, file_name: str):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file = os.path.join(output_dir, f\"{file_name}.csv\")\n",
    "    results.to_csv(output_file)\n",
    "    print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516e3829-ba21-41dc-92ec-d1b30263634f",
   "metadata": {},
   "source": [
    "# RQ1: Curated Vs. Non-Curated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2755f26-b64b-4db4-9ce1-18362d98ef36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ1_Curated_vs_Non_Curated/RQ1_Curated_Classification.csv\n",
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ1_Curated_vs_Non_Curated/RQ1_Non_Curated_Classification.csv\n",
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ1_Curated_vs_Non_Curated/RQ1_Curated_Regression.csv\n",
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ1_Curated_vs_Non_Curated/RQ1_Non_Curated_Regression.csv\n"
     ]
    }
   ],
   "source": [
    "def process_rq1(output_dir: str):\n",
    "    for task in ['Classification', 'Regression']:\n",
    "        for data_type in ['Curated', 'Non_Curated']:\n",
    "            dfs = []\n",
    "            for model in ['RF', 'ChemProp']:\n",
    "                df = read_csv_files(results_dirs[f\"{data_type}_{model}_{task}_Results\"])\n",
    "                dfs.append(df)\n",
    "            \n",
    "            combined_df = pd.concat(dfs)\n",
    "            results = aggregate_metrics(combined_df, metrics[task])\n",
    "            \n",
    "            save_results(pd.DataFrame(results).T, output_dir, f\"RQ1_{data_type}_{task}\")\n",
    "\n",
    "# Execute RQ1\n",
    "rq1_output_dir = os.path.join(base_dir, 'Results/Performance_Comparison/RQ1_Curated_vs_Non_Curated')\n",
    "process_rq1(rq1_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ace7165-7906-46e7-be25-9be8a30c055d",
   "metadata": {},
   "source": [
    "# RQ2: Scaffold Split Vs. Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96a57590-3d87-4dc3-a01a-837e236341b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ2_Scaffold_vs_Random_Split/RQ2_Classification_Scaffold.csv\n",
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ2_Scaffold_vs_Random_Split/RQ2_Classification_Random.csv\n",
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ2_Scaffold_vs_Random_Split/RQ2_Regression_Scaffold.csv\n",
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ2_Scaffold_vs_Random_Split/RQ2_Regression_Random.csv\n"
     ]
    }
   ],
   "source": [
    "def process_rq2(output_dir: str):\n",
    "    for task in ['Classification', 'Regression']:\n",
    "        dfs = [read_csv_files(results_dirs[f\"{data_type}_{model}_{task}_Results\"]) \n",
    "               for data_type in ['Curated', 'Non_Curated'] \n",
    "               for model in ['RF', 'ChemProp']]\n",
    "        \n",
    "        df = pd.concat(dfs)\n",
    "        \n",
    "        results = {}\n",
    "        for split_type in ['Scaffold', 'Random']:\n",
    "            split_df = df[df['split'].str.lower() == split_type.lower()]\n",
    "            results[split_type] = aggregate_metrics(split_df, metrics[task])\n",
    "        \n",
    "        for split_type, split_metrics in results.items():\n",
    "            save_results(pd.DataFrame(split_metrics).T, output_dir, f\"RQ2_{task}_{split_type}\")\n",
    "\n",
    "# Execute RQ2\n",
    "rq2_output_dir = os.path.join(base_dir, 'Results/Performance_Comparison/RQ2_Scaffold_vs_Random_Split')\n",
    "process_rq2(rq2_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b7039-0618-43e1-96ab-9c38467e71f0",
   "metadata": {},
   "source": [
    "# RQ3: Comparing Fingerprint Descriptor Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78a6bfd2-0ad4-4bce-bdf1-b12d42e3ba00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ3_Fingerprint_Performance/RQ3_RF_Classification_ECFP.csv\n",
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ3_Fingerprint_Performance/RQ3_RF_Classification_MACCS_KEYS.csv\n",
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ3_Fingerprint_Performance/RQ3_RF_Classification_AP2.csv\n",
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ3_Fingerprint_Performance/RQ3_RF_Classification_AP3.csv\n",
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ3_Fingerprint_Performance/RQ3_RF_Classification_AP2+AP3.csv\n",
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ3_Fingerprint_Performance/RQ3_RF_Regression_ECFP.csv\n",
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ3_Fingerprint_Performance/RQ3_RF_Regression_MACCS_KEYS.csv\n",
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ3_Fingerprint_Performance/RQ3_RF_Regression_AP2.csv\n",
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ3_Fingerprint_Performance/RQ3_RF_Regression_AP3.csv\n",
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ3_Fingerprint_Performance/RQ3_RF_Regression_AP2+AP3.csv\n"
     ]
    }
   ],
   "source": [
    "def process_rq3(output_dir: str):\n",
    "    for task in ['Classification', 'Regression']:\n",
    "        dfs = [read_csv_files(results_dirs[f\"{data_type}_RF_{task}_Results\"]) \n",
    "               for data_type in ['Curated', 'Non_Curated']]\n",
    "        df = pd.concat(dfs)\n",
    "        \n",
    "        results = {}\n",
    "        for fp_type in fingerprint_types:\n",
    "            fp_df = df[df['fingerprint'].str.lower() == fp_type.lower()]\n",
    "            if not fp_df.empty:\n",
    "                results[fp_type] = aggregate_metrics(fp_df, metrics[task])\n",
    "        \n",
    "        for fp_type, fp_metrics in results.items():\n",
    "            file_name = f\"RQ3_RF_{task}_{fp_type.replace(' ', '_')}\"\n",
    "            save_results(pd.DataFrame(fp_metrics).T, output_dir, file_name)\n",
    "\n",
    "# Execute RQ3\n",
    "rq3_output_dir = os.path.join(base_dir, 'Results/Performance_Comparison/RQ3_Fingerprint_Performance')\n",
    "process_rq3(rq3_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc32b57-7b33-4c2b-825c-f61790146cdf",
   "metadata": {},
   "source": [
    "# RQ4: RF Vs. ChemProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "020d0f36-38dd-40d4-b8be-881dc13c7957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ4_RF_vs_ChemProp/RQ4_Random_Forest_Classification.csv\n",
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ4_RF_vs_ChemProp/RQ4_ChemProp_Classification.csv\n",
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ4_RF_vs_ChemProp/RQ4_Random_Forest_Regression.csv\n",
      "Results saved to /Users/Avi/Dissertation/Results/Performance_Comparison/RQ4_RF_vs_ChemProp/RQ4_ChemProp_Regression.csv\n"
     ]
    }
   ],
   "source": [
    "def process_rq4(output_dir: str):\n",
    "    for task in ['Classification', 'Regression']:\n",
    "        for model in ['RF', 'ChemProp']:\n",
    "            dfs = [read_csv_files(results_dirs[f\"{data_type}_{model}_{task}_Results\"]) \n",
    "                   for data_type in ['Curated', 'Non_Curated']]\n",
    "            \n",
    "            combined_df = pd.concat(dfs)\n",
    "            results = aggregate_metrics(combined_df, metrics[task])\n",
    "            \n",
    "            results_df = pd.DataFrame({\n",
    "                'Mean': pd.DataFrame(results).T['mean'],\n",
    "                'Std': pd.DataFrame(results).T['std']\n",
    "            })\n",
    "            \n",
    "            model_name = 'Random_Forest' if model == 'RF' else 'ChemProp'\n",
    "            file_name = f\"RQ4_{model_name}_{task}\"\n",
    "            save_results(results_df, output_dir, file_name)\n",
    "\n",
    "# Execute RQ4\n",
    "rq4_output_dir = os.path.join(base_dir, 'Results/Performance_Comparison/RQ4_RF_vs_ChemProp')\n",
    "process_rq4(rq4_output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
